import numpy as np

#Selects the action using epsilon-greedy strategy

def epsilon_greedy_action(suggested_action, epsilon, actions, state):
    probability = np.random.random()
    if probability < (1 - epsilon) and suggested_action is not None:
        return suggested_action
    else:
        return np.random.choice(actions[state])

# Finds the key with the maximum value in a dictionary

def max_key_value(dictionary):
    max_key = max(dictionary, key=dictionary.get)
    return max_key, dictionary[max_key]

# Simulates a trip using reinforcement learning

def simulate_trip(actions, rewards, suggested_action, epsilon, state_returns, state_values, action_values):
    current_state = "Turin"
    trip_history = []

    while current_state != "Naples":
        action = epsilon_greedy_action(suggested_action[current_state], epsilon, actions, current_state)
        trip_history.append((current_state, action))

        if rewards[(current_state, action)] != -10:
            next_state = action
        else:
            next_state = current_state

        current_state = next_state

    gain = 0
    for state, action in reversed(trip_history):
        gain = gain + rewards[state, action]
        t = trip_history.index((state, action))

        if state not in [h[0] for h in trip_history][:t]:
            state_returns[state].append(gain)
            state_values[state] = np.average(state_returns[state])

            if rewards[(state, action)] != -10:
                next_state = action
            else:
                next_state = state

            action_values[(state, action)] = state_values[next_state] + rewards[(state, action)]

    return action_values

# Locations/specifies what cities are connected by roads

locations = ["Turin", "Milan", "Rome", "Naples"]
possible_actions = {
    "Turin": ["Milan", "Rome"],
    "Milan": ["Turin", "Rome"],
    "Rome": ["Turin", "Milan", "Naples"],
    "Naples": []
}

reward_values = {
    ("Turin", "Milan"): -1,
    ("Turin", "Rome"): -10,
    ("Milan", "Turin"): -1,
    ("Milan", "Rome"): -2,
    ("Rome", "Turin"): -10,
    ("Rome", "Milan"): -2,
    ("Rome", "Naples"): -3
}

state_returns = {state: [] for state in locations}
state_values = {state: 0 for state in locations}
action_values = {(state, action): 0 for state in locations for action in possible_actions[state]}
suggested_action = {state: None for state in locations}

# Algorithm for 10,000 iterations
for t in range(10000):
    action_values = simulate_trip(possible_actions, reward_values, suggested_action, 0.7, state_returns, state_values, action_values)
    for state in locations:
        actions_rewards = {}
        for a in possible_actions[state]:
            actions_rewards[a] = action_values[(state, a)]
        if actions_rewards:
            suggested_action[state] = max_key_value(actions_rewards)[0]

# Proposed actions
print("Proposed actions:")
for state in locations:
    print(f"{state} -> {suggested_action[state]}")
